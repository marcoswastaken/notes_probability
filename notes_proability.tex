\documentclass[10pt]{article}

\usepackage{amsmath, amssymb, amsthm}
\usepackage{enumerate}
\usepackage{multicol}

\usepackage[margin=.25in]{geometry}

\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\theoremstyle{theorem}
\newtheorem*{theorem}{Theorem}


\pagestyle{empty} %% Suppress page numbers
\setlength\parindent{0pt} %% Supress indentation


\begin{document}
		
		\section{Combinatorial Analysis}
		
		The \emph{basic principle of counting}: If an experiment consists of two phases, with $n$ possible outcomes in the first phase, and $m$ possible outcomes in the second phase for each of those outcomes, then the total possible number of outcomes is $nm$.
		
		There are $n!$ possible linear orderings of $n$ items.
		
		The number of distinct ways to choose $k$ items from $n$ without regard to order is given by
		
		\begin{align*}
			{n \choose k} = \frac{n!}{(n-k)!k!}
		\end{align*}
		
		For non-negative integers $n_1,n_2,\ldots, n_r$ with $\sum n_i = n$, the number distinct of ways to divide $n$ items into non-overlapping groups of sizes $n_1, n_2,\ldots, n_r$ is given by
		
		\begin{align*}
			{n \choose {n_1, n_2,\ldots, n_r}} = \frac{n!}{n_1!n_2! \cdots n_r!}
		\end{align*}
		
		\subsection*{Stars and Bars}
		For any positive integers $n$ and $k$, the number of $k$-tuples of positive integers that sum to $n$ is ${{n-1}\choose {k-1}}$\\
		For any positive integers $n$ and $k$, the number of $k$-tuples of non-negative integers that sum to $n$ is ${{n+k-1}\choose {k-1}}$
		\section{Axioms of Probability}
		
		Some notation and terminology:
		
		\begin{itemize}
			\item $S$ is the set of all possible outcomes of an experiment, a.k.a. the \emph{sample space}
			\item An \emph{event} is a subset of $S$
			\item For any event $A$ we define $A^c$ to be the complement of $A$ in $S$
			\item $S^c=\emptyset$ is the null set
			\item $A\cap B$ or sometimes $AB$ is the intersection of the sets $A$ and $B$. If $A\cap B = \emptyset$ then we say that $A$ and $B$ are mutually exclusive
		\end{itemize}
		
		\subsection*{Axioms}
		
		If $E$ is an event in a sample space $S$ then the probability that event $E$ occurs as the outcome of a single experiment is denoted by $P(E)$ and satisfies the following axioms
		
		\begin{enumerate}
			\item $0 \leq P(E) \leq 1$
			\item $P(S)=1$
			\item If $\left\{ E_i \right\}_{i=1}^\infty$ is a set of pairwise mutually exclusive events then $P(\cup_{i=1}^\infty)=\sum_{i=1}^\infty P(E_i)$
		\end{enumerate}
		
		\subsection*{Useful Results}
		
		\begin{align*}
			P(A^c) &= 1 - P(A)\\
			P(A \cup B) &= P(A) + P(B) - P(A \cap B)
		\end{align*}
		
		
		Informally, the generalization of this formula: add up all of the individual event probabilities, then subtract all of the double counted intersections, then add back all of the twice removed triple intersections, then remove all of the twice restored double counted quadruple intersections, etc.
		
		If $S$ is finite and every point in $S$ is assumed to have equal probability of occurring then
		
		\begin{align*}
			 P(A) = \frac{|A|}{|S|}
		\end{align*}
		
		\section{Conditional Probability and Independence}
		
		\subsection*{Conditional Probability}
		
		For events $E$ and $F$, the conditional probability of $E$ occurs, given that $F$ has occurred is denoted by  $P(E|F)$ and is defined by
		\begin{align*}
			P(E|F) 
				= \frac{P(E\cap F)}{P(F)}
				= \frac{P(F|E)P(E)}{P(F)}
				= \frac{P(F|E)P(E)}{P(F|E)P(E)+P(F|E^c)P(E^c)}
		\end{align*}
		where the last expression is \emph{Bayes's Formula}
		
		\subsection*{Independence}
		
		Two events are said to be \emph{independent} if $P(E\cap F) = P(E)P(F)$. Events that are not independent are said to be \emph{dependent}.  This generalizes to sets of events if every the probability of intersection of subsets is equal to the product of the probabilities of the individual events in the subset.
		
		\section{Random Variables}
		
		\subsection*{Random Variables}
		
		Given an experiment with sample space $S$, a \emph{random variable} is a real-valued function, $X$, defined on $S$. Because the value of a random variable is determined by the outcome of the experiment, we can assign probabilities to the possible values of the random variable, denoted by $P(X=x)$.
		
		\subsection*{Discrete Random Variables}
		If the range of $X$ is countable, $\left\{ x_1, x_2, \ldots \right\}$, then $X$ is said to be discrete. In this case we can define the \emph{probability mass function} $p:\mathbb{R}\to\mathbb{R}$ of $X$ to be $p(a) = P(X=a)$ which has the following properties:
		\begin{multicols}{3}
			\begin{enumerate}
				\item $p(x_i) \geq 0$ for $i=1,2,\ldots$
				\item $p(x) = 0$ for any other values of $x$
				\item $\sum_{i=1}^{\infty}p(x_i) = 1$
			\end{enumerate}
		\end{multicols}
		
		\subsection*{Expected Value}
		
		If $X$ is a discrete random variable with probability mass function $p(x)$ then the \emph{expected value} of $X$, denoted as $E[X]$ is defined by
		
		\begin{align*}
			E[X] = \sum_{xp(x)>0}xp(x)
		\end{align*}
		
		Some useful properties, for a random variable $X$ with non-zero outputs $\left\{ x_1, x_2, \ldots \right\}$: 
		
		\begin{itemize}
			\item If $g$ is any real value function then $E[g(X)] =  \sum_{i=1}^{\infty}g(x_i)p(x_i)$
			\item If $a$ and $b$ are constants, then $E[aX+b] = aE[X] + b $
		\end{itemize}
		
		\subsection*{Variance, Standard Deviation, Covariance, and Correlation}
		
		If $X$ is a random variable with \emph{mean} $\mu=E[X]$ then the variance of $X$, denoted by $\text{Var}(X)$, is defined to be $\text{Var}(X) = E[(X-\mu)^2]$
		
		Some useful formulas that follow from this definition:
		\begin{multicols}{2}
			\begin{itemize}
				\item $\text{Var}(X) = E[X^2] - (E[X])^2$
				\item $\text{Var}(aX + b) = a^2 \text{Var}(X)$
			\end{itemize}
		\end{multicols}
		
		The \emph{standard deviation} of $X$ is the square root of the variance: $\sigma = \sqrt{\text{Var}(X)}$
		
		Given random variables, $X$ and $Y$:
		\begin{itemize}
			\item $\text{Cov}(X,Y)=E[(X-E[X])(Y-E[Y])]=E[XY]-E[X]E[Y]$ and
			\begin{itemize}
				\item If $X$ and $Y$ are independent, then $E[XY]=E[X]E[Y]$, so $\text{Cov}(X,Y) = 0$
				\item $\text{Cov}(aX,bY)=ab\text{Cov}(X,Y)$
				\item $\text{Cov}(aX+bY,cZ)=ac\text{Cov}(X,Z) + bc\text{Cov}(Y,Z)$
			\end{itemize}
			\item $\text{Cor}(X,Y) =\frac{ \text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}}$
		\end{itemize} 
		Units of covariance are the products of the units of $X$ and $Y$, while correlation is unit-less.
		
		\subsection*{Bernoulli  Random Variable}
		
		A Bernoulli trial is an experiment that has two outcomes: \emph{success} or \emph{failure}. The sample space is $S=\left\{ \text{success}, \text{failure}\right\}$ and a \emph{Bernoulli random variable}, $X$, is defined by $X(\text{success})=1$ and $X(\text{failure}) = 0$, along with the probability mass function is given by
		\begin{align*}
			p(0) = P(X=0) = 1 - p  && p(0) = P(X=1) = p
		\end{align*}
		
		where $p$ is the probability of success in a given trial.
		\subsection*{Binomial Random Variable}
		A \emph{binomial random variable} is a random variable $X$ that represents the number of successes that occur in $n$ Bernoulli trials, each with probability of success $p$.
		
		Properties of Binomial Random Variables:
		\begin{multicols}{3}
			\begin{itemize}
				\item $P(X=k) = {n \choose k} p^{k} (1-p)^{n-k}$
				\item $E[X] = np$
				\item $\text{Var}(X)= np(1-p) $
			\end{itemize}
		\end{multicols}
		
		
		\subsection*{Poisson Random Variable}
		
		A \emph{Poisson Random Variable} is a random variable $X$ that takes on one of the values $0, 1, 2, \ldots$, or the number of successes that occur in a given interval, together with a parameter $\lambda > 0$ that describes the expected number of success in that interval.
		
		Properties of Poisson Random Variables:
		
		\begin{multicols}{3}
			\begin{itemize}
				\item $P(X=k) = e^{-\lambda} \: \dfrac{\lambda^k}{k!}$
				\item $E[X] = \lambda$
				\item $\text{Var}(X) = \lambda$
			\end{itemize}
		\end{multicols}
	
		\subsection*{Geometric Random Variable}
		A \emph{Geometric Random Variable} is a random variable $X$ that takes on one of the values $0, 1, 2, \ldots$, or the number of trials required until a success occurs, when repeatedly performing a Bernoulli trial with probability of success $p$.
		
		Properties of Geometric Random Variables:
		\begin{multicols}{3}
			\begin{itemize}
				\item $P(X=k) = p(1-p)^{k-1}$
				\item $E[X] = \frac{1}{p}$
				\item $\text{Var}(X)= \frac{1-p}{p^2} $
			\end{itemize}
		\end{multicols}
		
		\subsection*{Negative Binomial Random Variable}
		
		Suppose that independent Bernoulli trials, with proability of success $p$, are perfomed until $r$ successes occur. A \emph{negative binomial random variable} is a random variable $X$ that takes on one of the values $0, 1, 2, \ldots$, or the number of trials required.
		Properties of Negative Binomial Random Variables:
		
		\begin{multicols}{3}
			\begin{itemize}
				\item $P(X=k) = {{k-1} \choose {r-1}}p^r(1-p)^{k-r}$
				\item $E[X] = \frac{r}{p}$
				\item $\text{Var}(X)= \frac{r(1-p)}{p^2} $
			\end{itemize}
		\end{multicols}
		
		\subsection*{Hypergeometric Random Variables}
		A \emph{Hypergeometric Random Variable} is a random variable $X$ that takes on one of the values $0, 1, 2, \ldots$, describing the number of successes in $n$ draws, without replacement, from a finite population of size $N$, where exactly $K$ members are successes. (In contrast, a binomial random variable can be thought of as describing the probability of $k$ successes with replacement.)
		
			Properties of Hypergeometric Random Variables:
		\begin{multicols}{3}
			\begin{itemize}
				\item $P(X=k) = \dfrac{{K \choose k} {{N-k} \choose {n-k}}}{{N \choose n}}$
				\item $E[X] = \frac{nK}{N}$
				\item $\text{Var}(X)= n \frac{K}{N} \frac{N-K}{N} \frac{N-n}{n-1}$
			\end{itemize}
		\end{multicols}
		Note: $\text{Var}(X) \approx n(p)(1-p)$ when $N$ is large relative to $n$, where $p=K/N$.
		
		\subsection*{Expected Value and Sums of Random Variables}
		If $X_1, X_2, \ldots, X_n$ are random variables then
		\begin{align*}
			E \left[ \sum_{i=1}^{n} X_i \right] = \sum_{i=1}^{n} E[X_i]
		\end{align*}
		
		\newpage
		
		\section{Continuous Random Variables}
		We say that $X$ is a \emph{continuous random variable} if there exists a non-negative function $f$, defined on $\mathbb{R}$, with the property that, for any measurable set $B$ of real numbers, $P\left\{ X \in B \right\} = \int_{B} f(x)\: dx$, and $\int_{-\infty}^{\infty}f(x)\:dx = 1$. The function $f$ is called the \emph{probability density function} of the random variable $X$.
		
		The \emph{cumulative distribution function}, or just \emph{distribution function} of a continuous random variable is $F_X(x) = \int_{-\infty}^{x}f(t)\: dt$. Notice that the Fundamental Theorem of Calculus then gives us that \(f(x)=\frac{d}{dx}F(x)\).
		
		\subsection*{Expectation and Variance}
		If $X$ is a continuous random variable with probability density function $f(x)$ then the \emph{expected value} of $X$, denoted as $E[X]$ is defined by
		
		\begin{align*}
			E[X] = \int_{-\infty}^{\infty} xf(x)\:dx
		\end{align*}
		
		A useful property that follows from this definition is that, for any function $g$, $E[g(X)]=E[X] = \int_{-\infty}^{\infty} g(x)f(x)\:dx$ 
		
		If $X$ is a random variable with \emph{mean} $\mu=E[X]$ then the variance of $X$, denoted by $\text{Var}(X)$, is defined to be $\text{Var}(X) = E[(X-\mu)^2]$
		
		This definition is identical to the discrete case, and the same properties hold:
		\begin{multicols}{2}
			\begin{itemize}
				\item $\text{Var}(X) = E[X^2] - (E[X])^2$
				\item $\text{Var}(aX + b) = a^2 \text{Var}(x)$
			\end{itemize}
		\end{multicols}
		
		\subsection*{Uniform Random Variable}
		In general, we say that $X$ is a \emph{Uniform Random Variable} on the interval $(\alpha, \beta)$ if the probability of outcomes is even distributed among all outcomes in that interval. Properties of a Uniform Random Variable:
		\begin{multicols}{3}
			\begin{itemize}
				\item $f(x) = 
					\begin{cases} 
						\dfrac{1}{\beta - \alpha} & \text{if } \alpha < x < \beta\\
						0 & \text{otherwise}
					\end{cases}$
				\item $E(x) = \dfrac{\alpha + \beta}{2}$
				\item $\text{Var}(X) = \dfrac{(\beta-\alpha)^2}{12}$
			\end{itemize}
		\end{multicols}
		
		\subsection*{Normal Random Variable}
		In general, we say that $X$ is a \emph{Normal Random Variable} if the probability of outcomes is normally distributed with parameters \(\mu\) and \(\sigma^2\). Properties of a Normal Random Variabls:
		\begin{multicols}{3}
			\begin{itemize}
				\item $f(x) = \dfrac{1}{\sigma\sqrt{2\pi}}e^{-(x-\mu)^2 / 2\sigma^2}$
				\item $E(x) = \mu$
				\item $\text{Var}(X) = \sigma^2$
			\end{itemize}
		\end{multicols}
		If \(X\) is normal, with mean \(\mu\) and variance \(\sigma^2\) then $Z=\frac{X-\mu}{\sigma}$ is a \emph{standard} normal random variable with mean \(0\) and variance \(1\).
		
		A normal distribution can give a good approximation for a binomial random variable when \(np(1-p) \geq 10\).
		
		\subsection*{Exponential Random Variable}
		An \emph{Exponential Random Variable} is a random variable whose probability distribution models the distance between evens in a Poisson point process. Properties of an Exponential Random Variable:
		\begin{multicols}{3}
			\begin{itemize}
				\item $f(x) = 
				\begin{cases} 
					\lambda e ^ {-\lambda x} & \text{if }  x \geq 0 \\
					0 & \text{otherwise}
				\end{cases}$
				\item $E(x) = \dfrac{1}{\lambda}$
				\item $\text{Var}(X) = \dfrac{1}{\lambda^2}$
			\end{itemize}
		\end{multicols}
		A key property of exponential random variables is that they are \emph{memoryless}, so \(P\left\{X>s+t \mid X >t\right\} = P\left\{X > s \right\}\)
		
		\subsection*{Applications and Other Common Distributions}
		\subsubsection*{Failure Rate}
		Let \(X\) be a non-negative random variable that represents rate of survivors to time \(t\) during the next instant in time, with probability density function \(f(t)\) and cumulative density function \(F(t)\), then the \emph{failure rate} (or \emph{hazard rate}) is defined as \(h(t) = \dfrac{f(t)}{1-F(t)}\). For small values of \(dt\), \(h(t)\: dt\) is approximately the probability that a \(t\)-unit-old item will die within the next \(dt\)-time.
		
		In the special case that $F$ is the exponential distribution with parameter \(\lambda\), then the failure rate becomes constant with \(h(t)=\gamma\).
		
		\newpage
		
		\subsubsection*{Gamma Distribution}
		A \emph{gamma distribution} with shape parameter \(\alpha\) and scale parameter \(\lambda\) is defined in terms of the gamma function: \(\Gamma(\alpha)=\displaystyle\int_{0}^{\infty}e^{-x}x^{\alpha-1}\: dx\). 
		
		Gamma random variables are commonly used in modeling waiting times, or the distance between events in a Poisson point process.
		
		Properties of a Gamma Random Variable:
		\begin{multicols}{3}
			\begin{itemize}
				\item $f(x) = \dfrac{\lambda e^{\lambda x}(\lambda x)^{\alpha - 1}}{\Gamma(\alpha)}$
				\item $E(x) = \dfrac{\alpha}{\lambda}$
				\item $\text{Var}(X) = \frac{\alpha}{\lambda^2}$
			\end{itemize}
		\end{multicols}
		
		\subsubsection*{Beta Distribution}
		A \emph{beta distribution} with parameters \(a\) and \(b\) is defined in terms of the beta function: \(B(a,b)=\displaystyle\int_{0}^{1}x^{a-1}(1-x)^{b-1}\: dx\). 
		
		Beta random variables are commonly used in modeling the behavior of random variables limited to intervals of finite length, or the randome behavior of percentages or proportions.
		
		Properties of a Beta Random Variable for \(0 \leq x \leq 1\):
		\begin{multicols}{3}
			\begin{itemize}
				\item $f(x) = \dfrac{1}{B(a,b)}x^{a-1}(1-x)^{b-1}$
				\item $E(x) = \dfrac{a}{a+b}$
				\item $\text{Var}(X) = \dfrac{ab}{(a+b)^2(a+b+1)}$
			\end{itemize}
		\end{multicols}
		When \(a=b\) the beta density is symmetric about \(\frac{1}{2}\), and when \(b>a\) the density is skewed to the left (meaning smaller values are more likely).
		
		One connection between gamma and beta distributions is that \(B(a,b)=\dfrac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\)
		
		\section{Limit Theorems}
		
		\subsection*{Chebyshev's Inequality and the Weak Law of Large Numbers}
		
		\begin{theorem}[Markov's Inequality]
			If \(X\) is a random variable that takes on only non-negative values, then, for any \(a>0\), 
			\begin{align*}
				P\left\{X\geq a\right\} \leq \dfrac{E[X]}{a}
			\end{align*}
			
		\end{theorem}
		
		\begin{theorem}[Chebyshev's Inequality]
			If \(X\) is a random variable with finite mean \(\mu\) and variance \(\sigma^2\), then, for any value \(k>0\)
			\begin{align*}
				P\left\{| X-\mu | \geq k\right\} \leq \frac{\sigma^2}{k^2}
			\end{align*}
		\end{theorem}
		
		Note: If \(\bar{X}\) is the sample mean of \(n\)  independent and identically distributed observations from a populations with finite mean \(\mu\) and variance \(\sigma^2\), then we can apply Chebyshev's Inequality with \(E[\bar{X}]=\mu\) and \(\text{Var}(\bar{X})=\sigma^2/n\) to conclude that
		\begin{align*}
			P\left\{| \bar{X}-\mu | \geq k\right\} \leq \frac{\sigma^2}{nk^2}
		\end{align*}
		As \(n\) becomes large, the upper bound on this probability reaches zero. This leads to the proof of the Weak Law of Large Numbers.
		
		\begin{theorem}[The Weak Law of Large Numbers]
			Let \(X_1, X_2,\ldots\) be a sequence of independent and identically distributed random variables, each having finite mean \(E[X_i]=\mu\) and finite variance \(\sigma^2\). Then, for any \(\epsilon > 0\),
			\begin{align*}
				P \left\{ \left|\frac{X_1+X_2+\ldots + X_n}{n}-\mu \right| \geq \epsilon \right\} \to 0 \text{ as } n \to \infty
			\end{align*}
		\end{theorem}
		
		\subsection*{The Central Limit Theorem}
		
		\begin{theorem}[The Central Limit Theorem]
			Let \(X_1, X_2,\ldots\) be a sequence of independent and identically distributed random variables, each having finite mean \(E[X_i]=\mu\) and finite variance \(\sigma^2\). Then the distribution of
			\begin{align*}
				\frac{X_1 + X_2 + \cdots + X_n - n\mu}{\sigma \sqrt{n}}
			\end{align*}
			tends to the standard normal as \(n \to \infty\).
		\end{theorem}
		
		\section{Additional Topics}
		\subsection*{The Poisson Process}
		A function \(f\) is said to be \(o(h)\) if \(\lim\limits_{h \to 0}\frac{f(h)}{h}=0\). Intuitively, this means that for small values of \(h\), \(f(h)\) is small relative to \(h\).
		
		\begin{definition}
			Consider events that are occurring at random points in time, and let \(N(t)\) be the number of events that occurs in the interval \([0,t]\). The collection of random variables \(\left\{N(t), t \geq 0\right\}\) is a \emph{Poisson process having rate \(\lambda>0\)} if the folowing conditions are satisfied:
			\begin{enumerate}[(i)]
				\item \(N(0)=0\). The process starts at time \(0\).
				\item The number of events that occur in disjoint time intervals are independent.
				\item The distribution of the number of events that occur in a given interval depends only on the length of that interval (and not on its location)
				\item \(P\left\{N(h)=1\right\} = \lambda h + o(h)\)
				\item \(P\left\{N(h)\geq 2\right\} = o(h)\)
			\end{enumerate}
		\end{definition}
\end{document}